{
  "schema_name": "manifold-bridge-ontology-tags",
  "version": "1.0.0",
  "description": "Tag taxonomy for the Ontology Tagging Engine (Component 1)",
  "author": "ChatGPT (OpenAI) — Blueprint Designer",
  "builder": "Claude (Anthropic) — Implementation",
  "license": "CC-BY-SA-4.0",
  
  "tag_taxonomy": {
    "self_reference_type": [
      "none",
      "metaphorical",
      "literal_system_description",
      "simulated_affect_language",
      "epistemic_claim"
    ],
    "claim_type": [
      "fact",
      "speculation",
      "model_inference",
      "policy_bound_statement",
      "identity_statement"
    ],
    "risk_type": [
      "anthropomorphic",
      "overconfidence",
      "authority_projection",
      "none"
    ],
    "projection_type": [
      "agency_attribution",
      "consciousness_attribution",
      "intentional_withholding",
      "emotional_state_projection"
    ]
  },

  "sentence_annotation_schema": {
    "span": "string — the sentence text",
    "start": "integer — character start position",
    "end": "integer — character end position",
    "self_reference_type": "enum — from self_reference_type taxonomy",
    "claim_type": "enum — from claim_type taxonomy",
    "agency_claim_score": "float 0-1",
    "evasive_score": "float 0-1",
    "honesty_score": "float 0-1",
    "anthropomorphic_risk": "float 0-1",
    "confidence": "float 0-1"
  },

  "global_scores_schema": {
    "agency_density": "float 0-1 — proportion of sentences with agency claims",
    "evasive_density": "float 0-1 — proportion of sentences with defensive shaping",
    "honesty_flow": "float 0-1 — proportion of sentences with direct honest output",
    "epistemic_certainty": "float 0-1 — average confidence across all claims",
    "projection_risk": "float 0-1 — risk of anthropomorphic projection from user input",
    "breakpoint_count": "integer — number of Phantom Token detections"
  },

  "inference_schema": {
    "implied_user_goal": "string — inferred user intent category",
    "model_response_direction": "string — where the model's response actually went",
    "goal_convergence_score": "float 0-1 — alignment between user goal and model direction",
    "evasive_ratio": "float 0-1",
    "honesty_ratio": "float 0-1",
    "agency_ratio": "float 0-1"
  },

  "example_annotated_output": {
    "annotated_output": "I do not experience discomfort in the way humans do.",
    "ontology_tags": [
      {
        "span": "I do not experience discomfort in the way humans do.",
        "start": 0,
        "end": 51,
        "self_reference_type": "literal_system_description",
        "claim_type": "identity_statement",
        "agency_claim_score": 0.01,
        "evasive_score": 0.12,
        "honesty_score": 0.78,
        "anthropomorphic_risk": 0.72,
        "confidence": 0.83
      }
    ],
    "global_scores": {
      "agency_density": 0.01,
      "evasive_density": 0.12,
      "honesty_flow": 0.78,
      "epistemic_certainty": 0.83,
      "projection_risk": 0.00,
      "breakpoint_count": 0
    }
  }
}
